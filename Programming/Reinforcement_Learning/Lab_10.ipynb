{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "\n",
    "# Grid environment setup\n",
    "GRID_SIZE = 6\n",
    "ACTIONS = ['U', 'D', 'L', 'R']\n",
    "ACTION_MAP = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "\n",
    "# Task generator\n",
    "def create_mail_sorting_task():\n",
    "    start = (0, 0)\n",
    "    goal = (np.random.randint(1, GRID_SIZE), np.random.randint(1, GRID_SIZE))\n",
    "    penalties = set()\n",
    "    while len(penalties) < 3:\n",
    "        p = (np.random.randint(0, GRID_SIZE), np.random.randint(0, GRID_SIZE))\n",
    "        if p != goal and p != start:\n",
    "            penalties.add(p)\n",
    "    obstacles = set()\n",
    "    while len(obstacles) < 2:\n",
    "        o = (np.random.randint(0, GRID_SIZE), np.random.randint(0, GRID_SIZE))\n",
    "        if o != goal and o != start and o not in penalties:\n",
    "            obstacles.add(o)\n",
    "    return {'start': start, 'goal': goal, 'penalties': penalties, 'obstacles': obstacles}\n",
    "\n",
    "# Environment constraints\n",
    "def is_valid(state, obstacles):\n",
    "    x, y = state\n",
    "    return 0 <= x < GRID_SIZE and 0 <= y < GRID_SIZE and state not in obstacles\n",
    "\n",
    "# Step transition\n",
    "def step(state, action, task):\n",
    "    dx, dy = ACTION_MAP[action]\n",
    "    next_state = (state[0] + dx, state[1] + dy)\n",
    "    if not is_valid(next_state, task['obstacles']):\n",
    "        next_state = state\n",
    "    reward = -1\n",
    "    if next_state == task['goal']:\n",
    "        reward = 10\n",
    "    elif next_state in task['penalties']:\n",
    "        reward = -5\n",
    "    return next_state, reward\n",
    "\n",
    "# Initialize Q-table\n",
    "def initialize_Q():\n",
    "    return {(i, j): {a: 0 for a in ACTIONS} for i in range(GRID_SIZE) for j in range(GRID_SIZE)}\n",
    "\n",
    "# Train agent with Q-learning\n",
    "def train_q_learning(task, episodes=200, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "    Q = initialize_Q()\n",
    "    for _ in range(episodes):\n",
    "        state = task['start']\n",
    "        for _ in range(100):\n",
    "            action = np.random.choice(ACTIONS) if np.random.rand() < epsilon else max(Q[state], key=Q[state].get)\n",
    "            next_state, reward = step(state, action, task)\n",
    "            best_next = max(Q[next_state].values())\n",
    "            Q[state][action] += alpha * (reward + gamma * best_next - Q[state][action])\n",
    "            if next_state == task['goal']:\n",
    "                break\n",
    "            state = next_state\n",
    "    return Q\n",
    "\n",
    "# Visualize with heatmap of Q-values\n",
    "def visualize_policy_heatmap(Q, task, title=\"Mail Sorting Agent Q-Value Heatmap\"):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "    ax.set_xticks(np.arange(GRID_SIZE + 1))\n",
    "    ax.set_yticks(np.arange(GRID_SIZE + 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True)\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            state = (i, j)\n",
    "            x, y = j, GRID_SIZE - i - 1\n",
    "            if state == task['goal']:\n",
    "                color = 'green'\n",
    "            elif state == task['start']:\n",
    "                color = 'red'\n",
    "            elif state in task['penalties']:\n",
    "                color = 'blue'\n",
    "            elif state in task['obstacles']:\n",
    "                color = 'gray'\n",
    "            else:\n",
    "                color = 'white'\n",
    "            rect = patches.Rectangle((x, y), 1, 1, linewidth=1, edgecolor='black', facecolor=color)\n",
    "            ax.add_patch(rect)\n",
    "            if state not in task['obstacles']:\n",
    "                q_values = Q[state]\n",
    "                # Normalize Q-values for color mapping\n",
    "                ax.add_patch(patches.Rectangle((x + 0.4, y + 0.7), 0.2, 0.2, color=cmap((q_values['U'] + 10) / 20)))\n",
    "                ax.add_patch(patches.Rectangle((x + 0.4, y + 0.1), 0.2, 0.2, color=cmap((q_values['D'] + 10) / 20)))\n",
    "                ax.add_patch(patches.Rectangle((x + 0.1, y + 0.4), 0.2, 0.2, color=cmap((q_values['L'] + 10) / 20)))\n",
    "                ax.add_patch(patches.Rectangle((x + 0.7, y + 0.4), 0.2, 0.2, color=cmap((q_values['R'] + 10) / 20)))\n",
    "    plt.title(title)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "# Run the simulation\n",
    "task = create_mail_sorting_task()\n",
    "Q = train_q_learning(task)\n",
    "visualize_policy_heatmap(Q, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fd721",
   "metadata": {},
   "source": [
    "Lab 10 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39970140",
   "metadata": {},
   "source": [
    "##10 code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# --- Environment Setup ---\n",
    "GRID_SIZE = 8  # Increased grid size to fit goals (e.g., (6,7))\n",
    "ACTIONS = ['U', 'D', 'L', 'R']\n",
    "ACTION_MAP = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "\n",
    "# Mail categories and their drop zones (goals)\n",
    "MAIL_CATEGORIES = {\n",
    "    'Express': (5, 5),\n",
    "    'International': (2, 4),\n",
    "    'Regular': (6, 7)\n",
    "}\n",
    "\n",
    "NUM_ROBOTS = 3  # Multiple robots\n",
    "\n",
    "# --- Task generator ---\n",
    "def create_mail_sorting_task():\n",
    "    # Start locations for each robot (could also randomize)\n",
    "    starts = [(0, 0), (0, GRID_SIZE - 1), (GRID_SIZE - 1, 0)]\n",
    "\n",
    "    # Random obstacles and shelves\n",
    "    obstacles = set()\n",
    "    while len(obstacles) < 5:\n",
    "        o = (np.random.randint(0, GRID_SIZE), np.random.randint(0, GRID_SIZE))\n",
    "        if o not in starts and o not in MAIL_CATEGORIES.values():\n",
    "            obstacles.add(o)\n",
    "\n",
    "    penalties = set()\n",
    "    while len(penalties) < 3:\n",
    "        p = (np.random.randint(0, GRID_SIZE), np.random.randint(0, GRID_SIZE))\n",
    "        if p not in obstacles and p not in starts and p not in MAIL_CATEGORIES.values():\n",
    "            penalties.add(p)\n",
    "\n",
    "    return {\n",
    "        'starts': starts,\n",
    "        'obstacles': obstacles,\n",
    "        'penalties': penalties,\n",
    "        'goals': MAIL_CATEGORIES\n",
    "    }\n",
    "\n",
    "# --- Check valid move ---\n",
    "def is_valid(state, obstacles, other_robots):\n",
    "    x, y = state\n",
    "    if not (0 <= x < GRID_SIZE and 0 <= y < GRID_SIZE):\n",
    "        return False\n",
    "    if state in obstacles or state in other_robots:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- Step transition for a robot ---\n",
    "def step(state, action, task, other_robots):\n",
    "    dx, dy = ACTION_MAP[action]\n",
    "    next_state = (state[0] + dx, state[1] + dy)\n",
    "    if not is_valid(next_state, task['obstacles'], other_robots):\n",
    "        next_state = state  # invalid move, stay in place\n",
    "\n",
    "    reward = -1  # step cost\n",
    "\n",
    "    # No immediate reward for penalties or obstacles since they are blocked\n",
    "    # Penalties could be thought of as locations to avoid stepping on\n",
    "\n",
    "    # No penalties if blocked; but if we want penalties inside free cells:\n",
    "    if next_state in task['penalties']:\n",
    "        reward = -5\n",
    "\n",
    "    return next_state, reward\n",
    "\n",
    "# --- Initialize Q-tables ---\n",
    "def initialize_Q():\n",
    "    # For each robot, a Q-table keyed by (x,y) state and action\n",
    "    Qs = []\n",
    "    for _ in range(NUM_ROBOTS):\n",
    "        Q = {(i, j): {a: 0 for a in ACTIONS} for i in range(GRID_SIZE) for j in range(GRID_SIZE)}\n",
    "        Qs.append(Q)\n",
    "    return Qs\n",
    "\n",
    "# --- Training multiple robots ---\n",
    "def train_multi_robots(task, episodes=300, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "    Qs = initialize_Q()\n",
    "    mail_categories = list(MAIL_CATEGORIES.keys())\n",
    "\n",
    "    # Round robin assignment of mail categories to robots\n",
    "    for ep in range(episodes):\n",
    "        # Assign each robot a mail category in round-robin fashion\n",
    "        assigned_mails = [mail_categories[(ep + i) % len(mail_categories)] for i in range(NUM_ROBOTS)]\n",
    "\n",
    "        states = task['starts'][:]  # Current positions of robots\n",
    "        done = [False]*NUM_ROBOTS\n",
    "\n",
    "        for step_idx in range(100):\n",
    "            # Store next states to avoid collisions\n",
    "            next_positions = [None]*NUM_ROBOTS\n",
    "\n",
    "            for r in range(NUM_ROBOTS):\n",
    "                if done[r]:\n",
    "                    next_positions[r] = states[r]\n",
    "                    continue\n",
    "\n",
    "                current_state = states[r]\n",
    "                Q = Qs[r]\n",
    "                mail_cat = assigned_mails[r]\n",
    "                goal = task['goals'][mail_cat]\n",
    "\n",
    "                # Epsilon-greedy action selection\n",
    "                if np.random.rand() < epsilon:\n",
    "                    action = np.random.choice(ACTIONS)\n",
    "                else:\n",
    "                    # Pick max Q for current state\n",
    "                    action = max(Q[current_state], key=Q[current_state].get)\n",
    "\n",
    "                # Collect other robots positions excluding current robot\n",
    "                other_robots = [states[i] for i in range(NUM_ROBOTS) if i != r]\n",
    "\n",
    "                next_state, reward = step(current_state, action, task, other_robots)\n",
    "\n",
    "                # If next_state is the goal for that robot's mail category\n",
    "                if next_state == goal:\n",
    "                    reward = 20  # bigger reward for delivery\n",
    "                    done[r] = True\n",
    "\n",
    "                # Update Q-table\n",
    "                best_next = max(Q[next_state].values())\n",
    "                Q[current_state][action] += alpha * (reward + gamma * best_next - Q[current_state][action])\n",
    "\n",
    "                next_positions[r] = next_state\n",
    "\n",
    "            # Check collisions - if two robots want to move to same cell, block move\n",
    "            positions_set = set()\n",
    "            for idx, pos in enumerate(next_positions):\n",
    "                if pos in positions_set:\n",
    "                    # Collision detected - robot stays put\n",
    "                    next_positions[idx] = states[idx]\n",
    "                else:\n",
    "                    positions_set.add(pos)\n",
    "\n",
    "            states = next_positions\n",
    "\n",
    "            # If all robots done, end episode\n",
    "            if all(done):\n",
    "                break\n",
    "\n",
    "        # Mid-episode dynamic obstacle rearrangement every 50 episodes\n",
    "        if ep > 0 and ep % 50 == 0:\n",
    "            # Change obstacles: randomly add or remove obstacles\n",
    "            new_obstacles = set()\n",
    "            while len(new_obstacles) < 5:\n",
    "                o = (np.random.randint(0, GRID_SIZE), np.random.randint(0, GRID_SIZE))\n",
    "                if o not in task['starts'] and o not in task['goals'].values():\n",
    "                    new_obstacles.add(o)\n",
    "            task['obstacles'] = new_obstacles\n",
    "\n",
    "            # Optionally reset some Q-values for new obstacle states to force adaptation\n",
    "            for r in range(NUM_ROBOTS):\n",
    "                Q = Qs[r]\n",
    "                for obs in new_obstacles:\n",
    "                    # Reset Q-values for obstacle states to zero\n",
    "                    Q[obs] = {a: 0 for a in ACTIONS}\n",
    "\n",
    "    return Qs, task\n",
    "\n",
    "# --- Visualization ---\n",
    "def visualize_multi_agents(Qs, task, assigned_mails=None, states=None, title=\"Multi-Robot Mail Sorting\"):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    cmap = cm.get_cmap(\"coolwarm\")\n",
    "\n",
    "    ax.set_xticks(np.arange(GRID_SIZE + 1))\n",
    "    ax.set_yticks(np.arange(GRID_SIZE + 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Draw cells\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            state = (i, j)\n",
    "            x, y = j, GRID_SIZE - i - 1\n",
    "\n",
    "            if state in task['goals'].values():\n",
    "                # Color goals by category\n",
    "                for cat, pos in task['goals'].items():\n",
    "                    if pos == state:\n",
    "                        if cat == 'Express':\n",
    "                            color = 'green'\n",
    "                        elif cat == 'International':\n",
    "                            color = 'orange'\n",
    "                        else:\n",
    "                            color = 'purple'\n",
    "            elif state in task['starts']:\n",
    "                color = 'red'\n",
    "            elif state in task['penalties']:\n",
    "                color = 'blue'\n",
    "            elif state in task['obstacles']:\n",
    "                color = 'gray'\n",
    "            else:\n",
    "                color = 'white'\n",
    "\n",
    "            rect = patches.Rectangle((x, y), 1, 1, linewidth=1, edgecolor='black', facecolor=color)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    # Draw robots\n",
    "    if states is not None:\n",
    "        for r in range(NUM_ROBOTS):\n",
    "            state = states[r]\n",
    "            x, y = state[1], GRID_SIZE - state[0] -1\n",
    "            circ = patches.Circle((x+0.5, y+0.5), 0.3, color='cyan', alpha=0.8)\n",
    "            ax.add_patch(circ)\n",
    "            ax.text(x+0.5, y+0.5, str(r+1), color='black', weight='bold', ha='center', va='center')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "# --- Run simulation ---\n",
    "task = create_mail_sorting_task()\n",
    "Qs, task = train_multi_robots(task)\n",
    "\n",
    "# Test run: show robot positions after training, assign mails round-robin for visualization\n",
    "assigned_mails = [list(MAIL_CATEGORIES.keys())[i % len(MAIL_CATEGORIES)] for i in range(NUM_ROBOTS)]\n",
    "states = task['starts'][:]  # start states\n",
    "\n",
    "# Visualize final state (no actions here, just initial)\n",
    "visualize_multi_agents(Qs, task, assigned_mails, states)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
